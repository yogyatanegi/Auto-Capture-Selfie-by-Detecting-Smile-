{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream thread...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     14\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 15\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mfaceCascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x,y,w,h) \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     23\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(img,(x,y),(x\u001b[38;5;241m+\u001b[39mw,y\u001b[38;5;241m+\u001b[39mh),(\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#HAAR Selfie App\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    " \n",
    "print(\"[INFO] starting video stream thread...\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "counter = 0\n",
    "selfie_no = 0\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,      \n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "                \n",
    "        smile = smileCascade.detectMultiScale(\n",
    "            roi_gray,\n",
    "            scaleFactor= 1.5,\n",
    "            minNeighbors=15,\n",
    "            minSize=(25, 25),\n",
    "            )\n",
    "        \n",
    "        for i in smile:\n",
    "            if len(smile)>1.97:\n",
    "                cv2.putText(img,\"Smile Detected\",(x-30,y-30),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),3,cv2.LINE_AA)\n",
    "                counter = counter + 1\n",
    "                \n",
    "                if counter > 20:\n",
    "                    cv2.putText(img,\"3\",(10,90),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                \n",
    "                if counter > 40:\n",
    "                    cv2.putText(img,\"2\",(30,90),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                    \n",
    "                if counter > 60:\n",
    "                    cv2.putText(img,\"1\",(50,90),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                    \n",
    "                if counter > 80 :\n",
    "                    ret, img1 = cap.read()   \n",
    "                    cv2.putText(img,\"Captured\",(10, 120), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "                \n",
    "                if counter == 90 :\n",
    "                    selfie_no = selfie_no+1\n",
    "                    img_name = \"images/haar_webcam/haar_smart_selfie_{}.png\".format(selfie_no)\n",
    "                    time.sleep(2)\n",
    "                    cv2.imwrite(img_name,img1)\n",
    "                    counter = 0\n",
    "                    \n",
    "            else:\n",
    "                counter = 0\n",
    "                \n",
    "               \n",
    "    cv2.imshow('Live Capture', img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: # press 'ESC' to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"[INFO] video stream ended..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test image HAAR \n",
    "\n",
    "pos_dir = \"dataset/images/positives/\"\n",
    "neg_dir = \"dataset/images/negatives/\"\n",
    "\n",
    "def HAAR_image(img, file):\n",
    "    smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "    \n",
    "    scale_percent = 200 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "                       \n",
    "    smile = smileCascade.detectMultiScale(\n",
    "                resized_img,\n",
    "                scaleFactor= 1.5,\n",
    "                minNeighbors=15,\n",
    "                minSize=(25, 25),\n",
    "            )\n",
    "                \n",
    "    for i in smile:\n",
    "        if len(smile)>1.97:\n",
    "            file_split = file.split('\\\\')\n",
    "            file_split1 = file_split[1].split('.')\n",
    "            filename = 'images/negative_haar/' + file_split1[0] + '.png' #change directory\n",
    "            cv2.imwrite(filename,resized_img)                       \n",
    "\n",
    "\n",
    "#to call all image files from dataset \n",
    "data_path = os.path.join(neg_dir, '*g')  #change positive/negative dataset\n",
    "files = glob.glob(data_path)\n",
    "data = [] \n",
    "for f1 in files: \n",
    "    image = cv2.imread(f1) \n",
    "    data.append(image)\n",
    "    HAAR_image(image, f1)\n",
    "\n",
    "print(\"[INFO] End of image...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame from video\n",
    " \n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture('dataset/videos/Make People Smile Project.mp4')\n",
    "i = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    i = i + 1\n",
    "    img_name = \"dataset/videos/video_actual/frame{}.png\".format(i)\n",
    "    cv2.imwrite(img_name,frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream thread...\n",
      "[INFO] video stream ended..\n"
     ]
    }
   ],
   "source": [
    "#test video HAAR\n",
    "\n",
    "def HAAR_video(file):\n",
    "    frame_no = 0\n",
    "    eyeCascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    smileCascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    " \n",
    "    print(\"[INFO] starting video stream thread...\")\n",
    "    cap = cv2.VideoCapture(file)\n",
    "\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = eyeCascade.detectMultiScale(gray)\n",
    "\n",
    "        frame_no = frame_no + 1\n",
    "        \n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(gray,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "            smile = smileCascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor= 1.5,\n",
    "                minNeighbors=15,\n",
    "                minSize=(25, 25),\n",
    "                )\n",
    "\n",
    "            for i in smile:\n",
    "                if len(smile)>1.97:\n",
    "                    cv2.putText(img,\"Smile Detected\",(10,90),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),3,cv2.LINE_AA)\n",
    "                    ret, img1 = cap.read()\n",
    "                    frame_no = frame_no + 1\n",
    "                    cv2.putText(img,\"Captured\",(10, 120), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 2)\n",
    "                    img_name = \"images/video_haar/haar_video_test_{}.png\".format(frame_no)\n",
    "                    cv2.imwrite(img_name,img1)\n",
    "                    \n",
    "\n",
    "        cv2.imshow('Video Test', img)\n",
    "        \n",
    "        key2 = cv2.waitKey(1) & 0xFF\n",
    "        if key2 == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] video stream ended..\")\n",
    "    \n",
    "video = 'dataset/videos/Make People Smile Project.mp4'\n",
    "HAAR_video(video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
